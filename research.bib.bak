% Encoding: UTF-8

@InProceedings{Karras2021,
  author    = {Tero Karras and Miika Aittala and Samuli Laine and Erik H\"ark\"onen and Janne Hellsten and Jaakko Lehtinen and Timo Aila},
  booktitle = {Proc. NeurIPS},
  title     = {Alias-Free Generative Adversarial Networks},
  year      = {2021},
  file      = {:Karras2021 - Alias Free Generative Adversarial Networks.pdf:PDF},
  keywords  = {Image synthesis, GAN},
  timestamp = {2021-10-21},
  url       = {https://nvlabs.github.io/stylegan3/},
}

@Article{Karras2019,
  author        = {Tero Karras and Samuli Laine and Miika Aittala and Janne Hellsten and Jaakko Lehtinen and Timo Aila},
  title         = {Analyzing and Improving the Image Quality of StyleGAN},
  year          = {2019},
  month         = dec,
  abstract      = {The style-based GAN architecture (StyleGAN) yields state-of-the-art results in data-driven unconditional generative image modeling. We expose and analyze several of its characteristic artifacts, and propose changes in both model architecture and training methods to address them. In particular, we redesign the generator normalization, revisit progressive growing, and regularize the generator to encourage good conditioning in the mapping from latent codes to images. In addition to improving image quality, this path length regularizer yields the additional benefit that the generator becomes significantly easier to invert. This makes it possible to reliably attribute a generated image to a particular network. We furthermore visualize how well the generator utilizes its output resolution, and identify a capacity problem, motivating us to train larger models for additional quality improvements. Overall, our improved model redefines the state of the art in unconditional image modeling, both in terms of existing distribution quality metrics as well as perceived image quality.},
  archiveprefix = {arXiv},
  eprint        = {1912.04958},
  file          = {:Generative model/1912 StyleGAN2 - Analyzing and Improving the Image Quality of StyleGAN (Karras).pdf:PDF},
  keywords      = {cs.CV, cs.LG, cs.NE, eess.IV, stat.ML},
  primaryclass  = {cs.CV},
}

@Article{Karras2020,
  author        = {Tero Karras and Miika Aittala and Janne Hellsten and Samuli Laine and Jaakko Lehtinen and Timo Aila},
  journal       = {NeurIPS},
  title         = {Training Generative Adversarial Networks with Limited Data},
  year          = {2020},
  month         = jun,
  abstract      = {Training generative adversarial networks (GAN) using too little data typically leads to discriminator overfitting, causing training to diverge. We propose an adaptive discriminator augmentation mechanism that significantly stabilizes training in limited data regimes. The approach does not require changes to loss functions or network architectures, and is applicable both when training from scratch and when fine-tuning an existing GAN on another dataset. We demonstrate, on several datasets, that good results are now possible using only a few thousand training images, often matching StyleGAN2 results with an order of magnitude fewer images. We expect this to open up new application domains for GANs. We also find that the widely used CIFAR-10 is, in fact, a limited data benchmark, and improve the record FID from 5.59 to 2.42.},
  archiveprefix = {arXiv},
  eprint        = {2006.06676},
  file          = {:Karras2020 - Training Generative Adversarial Networks with Limited Data.pdf:PDF;:Generative model/2012NIPS training GAN with limited data.pdf:PDF},
  keywords      = {cs.CV, cs.LG, cs.NE, stat.ML},
  primaryclass  = {cs.CV},
}

@Article{Karras2018,
  author        = {Tero Karras and Samuli Laine and Timo Aila},
  journal       = {CVPR},
  title         = {A Style-Based Generator Architecture for Generative Adversarial Networks},
  year          = {2018},
  month         = dec,
  abstract      = {We propose an alternative generator architecture for generative adversarial networks, borrowing from style transfer literature. The new architecture leads to an automatically learned, unsupervised separation of high-level attributes (e.g., pose and identity when trained on human faces) and stochastic variation in the generated images (e.g., freckles, hair), and it enables intuitive, scale-specific control of the synthesis. The new generator improves the state-of-the-art in terms of traditional distribution quality metrics, leads to demonstrably better interpolation properties, and also better disentangles the latent factors of variation. To quantify interpolation quality and disentanglement, we propose two new, automated methods that are applicable to any generator architecture. Finally, we introduce a new, highly varied and high-quality dataset of human faces.},
  archiveprefix = {arXiv},
  eprint        = {1812.04948},
  file          = {:Generative model/1812CVPR StyleGAN - A Style-Based Generator Architecture for Generative Adversarial Networks (Karras).pdf:PDF},
  keywords      = {cs.NE, cs.LG, stat.ML},
  primaryclass  = {cs.NE},
}

@Article{Karras2017,
  author        = {Tero Karras and Timo Aila and Samuli Laine and Jaakko Lehtinen},
  journal       = {ICLR},
  title         = {Progressive Growing of GANs for Improved Quality, Stability, and Variation},
  year          = {2017},
  month         = oct,
  abstract      = {We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024^2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset.},
  archiveprefix = {arXiv},
  eprint        = {1710.10196},
  file          = {:Generative model/1710ICLR PG-GAN Progressive Growing of GANs for Improved Quality, Stability, and Variation (Karras).pdf:PDF},
  keywords      = {cs.NE, cs.LG, stat.ML},
  primaryclass  = {cs.NE},
}

@Comment{jabref-meta: databaseType:bibtex;}
